{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.A: Working with Datasets\n",
    "\n",
    "It's important to have a clear and sensible way of representing the datasets that learning algorithms train on. A dataset consists of $n$ examples. Each example consists of $m$ features. This makes $m$ the number dimensions the dataset has. In supervised learning, the dataset is a matrix like this:\n",
    "\n",
    "$\\boldsymbol{D} =\\left[\\begin{array}{cccccc} \n",
    "  x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & \\cdots & x_m^{(1)} & y^{(1)}\\\\ \n",
    "  x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & \\cdots & x_m^{(2)} & y^{(2)}\\\\\n",
    "  x_1^{(3)} & x_2^{(3)} & x_3^{(3)} & \\cdots & x_m^{(3)} & y^{(3)}\\\\\n",
    "  \\vdots    & \\vdots    & \\vdots    & \\cdots & \\vdots & \\vdots \\\\\n",
    "  x_1^{(n)} & x_2^{(n)} & x_3^{(n)} & \\cdots & x_m^{(n)} & y^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "Each row of this matrix is an example consisting of the $m$ features plus the target label as the last element in the row. In other words, $\\boldsymbol{D}$ consists of both the input matrix $\\boldsymbol{X}$ and target vector $y$, where: \n",
    "\n",
    "$\\boldsymbol{X} =\\left[\\begin{array}{ccccc} \n",
    "  x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & \\cdots & x_m^{(1)}\\\\ \n",
    "  x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & \\cdots & x_m^{(2)}\\\\\n",
    "  x_1^{(3)} & x_2^{(3)} & x_3^{(3)} & \\cdots & x_m^{(3)}\\\\\n",
    "  \\vdots    & \\vdots    & \\vdots    & \\cdots & \\vdots \\\\\n",
    "  x_1^{(n)} & x_2^{(n)} & x_3^{(n)} & \\cdots & x_m^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "and\n",
    "\n",
    "$\\boldsymbol{y} =\\left[\\begin{array}{c} \n",
    "  y^{(1)}\\\\ \n",
    "  y^{(2)}\\\\\n",
    "  y^{(3)}\\\\\n",
    "  \\vdots \\\\\n",
    "  y^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "For unsupervised learning, $\\boldsymbol{D}$ is the same as $\\boldsymbol{X}$. Here is a class named `DataSet` to represent datasets. It uses pandas' DataFrame.\n",
    "\n",
    "Another name for $X$ is `inputs`, and another name for $y$ is `target`. In addition, features have names. Let's put all of this together in a class that we will be using in subsequent weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    A dataset for a machine learning problem. A dataset d has the following properties:\n",
    "    d.examples   A list of examples. Each one contains both the features and the target.\n",
    "    d.features   An array of the of feature names.\n",
    "    d.target     An m by 1 array containing the values of y\n",
    "    d.y          Same as d.target\n",
    "    d.inputs     An n by m array containing the values of X\n",
    "    d.X          Same as d.inputs\n",
    "    d.N          Number of examples\n",
    "    d.M          Number of dimensions\n",
    "    d.name       The name of the data set (for output display only)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, features=None, y=None, name=None):\n",
    "        \"\"\"\n",
    "        If y is True, the data contains the target as the last column\n",
    "        If y is None or False, No target is available\n",
    "        Else y is an array to be added as the last column of the examples  dataframe\n",
    "        \"\"\"\n",
    "        self.__name = name\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            self.__examples = data\n",
    "        else:\n",
    "            self.__examples = pd.DataFrame(data, columns=features)\n",
    "            \n",
    "        if y is True:\n",
    "            self.__examples.columns = [*self.__examples.columns[:-1], 'y']\n",
    "        elif y is not False and y is not None:\n",
    "            self.__examples['y'] = y\n",
    "    \n",
    "    @property\n",
    "    def examples(self):\n",
    "        return self.__examples\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__examples.columns[:-1].values\n",
    "    \n",
    "    @property\n",
    "    def target(self):\n",
    "        if 'y' in self.__examples.columns:\n",
    "            return self.__examples['y'].values.reshape(self.N, 1)\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.target\n",
    "    \n",
    "    @property\n",
    "    def inputs(self):\n",
    "        return self.__examples.iloc[:, :-1].values\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.inputs\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "    \n",
    "    @property\n",
    "    def N(self):\n",
    "        return self.__examples.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def M(self):\n",
    "        return self.inputs.shape[1]\n",
    "    \n",
    "    def shuffled(self, random_state=None):\n",
    "        rgen = np.random.RandomState(random_state)\n",
    "        indexes = np.arange(self.N)\n",
    "        rgen.shuffle(indexes)\n",
    "        return DataSet(self.__examples.iloc[indexes])\n",
    "    \n",
    "    def train_test_split(self, start=0, end=None, test_portion=None, shuffle=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the dataset into a training set and a test set. \n",
    "        If test_portion is specified, return that portion of the dataset as test \n",
    "        and the rest as training. \n",
    "        Otherwise, return the examples between start and end as test and the \n",
    "        rest as training.\n",
    "        \"\"\"\n",
    "        indexes = np.arange(self.N)\n",
    "        if shuffle is True:\n",
    "            rgen = np.random.RandomState(random_state)\n",
    "            rgen.shuffle(indexes)\n",
    "\n",
    "        if test_portion is None:\n",
    "            end = end or self.N\n",
    "        else:\n",
    "            if not isinstance(test_portion, float) or test_portion < 0 or test_portion > 1:\n",
    "                raise TypeError(\"Only fractions between ]0,1[ are allowed\")\n",
    "\n",
    "            start = self.N - int(self.N * test_portion)\n",
    "            end = self.N\n",
    "\n",
    "        test = DataSet(self.examples.iloc[indexes[range(start, end)]])\n",
    "        train = DataSet(pd.concat([self.examples.iloc[indexes[range(start)]], \n",
    "                                      self.examples.iloc[indexes[range(end, self.N)]]], axis=0))    \n",
    "        return train, test\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.examples)\n",
    "    \n",
    "    '''\n",
    "    My Section of the code for the excerise\n",
    "    '''\n",
    "    def train_validation_test_split(self, portions, shuffle=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the data into train, validation, and test sets.\n",
    "        Will receive a dictionary parameter named portions specifying \n",
    "        how much of the data is in each set.\n",
    "        \"\"\"\n",
    "        \n",
    "        indexes = np.arange(self.N)\n",
    "        if shuffle is True:\n",
    "            rgen = np.random.RandomState(random_state)\n",
    "            rgen.shuffle(indexes)\n",
    "            \n",
    "        'Use Dictionary.get() to get the values out of the portions'\n",
    "        trainVal = portions.get(\"training\")\n",
    "        validVal = portions.get(\"validation\")\n",
    "        testVal = portions.get(\"test\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Here we are using train_test_split to break the set into its first two parts.\n",
    "        We will have the set of data remaining (the validation and training) and the\n",
    "        test set\n",
    "        \"\"\"\n",
    "        dataLeft, test = self.train_test_split(test_portion=testVal, shuffle=False)\n",
    "        \n",
    "        '''\n",
    "        We will then find the portion of the remaining data that will be used for validation\n",
    "        by using the original vaildVal to find the total number in the original dataset.\n",
    "        Then we will get a new percentage by taking that number and dividing it by the new\n",
    "        total in the new dataset.\n",
    "        '''\n",
    "        validStart = self.N - int(self.N * validVal)\n",
    "        \n",
    "        validPortion = validStart/dataLeft.N\n",
    "        \n",
    "        \"\"\"\n",
    "        We will then do the train_test_split on our new dataLeft set to get our validation and training sets\n",
    "        \"\"\"\n",
    "        \n",
    "        train, validation = dataLeft.train_test_split(test_portion=1-validPortion, shuffle=False)\n",
    "        \n",
    "        return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class has a couple of properties including `name` (informational), `features` (the names of the features), `inputs`, `target`, `X`, `y`, `N` (number of examples), `M` (number of dimensions).\n",
    "\n",
    "A DataSet object is created using a NumPy array or a Pandas dataframe. If it is a NumPy array, the class uses it to create a Pandas dataframe. The dataframe storing the data can be retrieved back using the `examples` property.\n",
    "\n",
    "\n",
    "Let's test this class by creating a $27 \\times 3$ input data and a separate $y$ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     x1   x2         x1  y\n",
       "0   7.0  5.0  14.071137  0\n",
       "1   7.0  4.0  10.999822  0\n",
       "2   5.0  6.0  11.821084  1\n",
       "3   6.0  3.0   8.643734  0\n",
       "4   8.0  7.0   9.530007  1\n",
       "5   2.0  5.0   9.314699  0\n",
       "6   7.0  8.0   9.542695  1\n",
       "7   5.0  8.0  10.032778  0\n",
       "8   7.0  4.0  13.806657  1\n",
       "9   5.0  6.0  11.252529  1\n",
       "10  6.0  4.0   9.952814  1\n",
       "11  5.0  7.0  10.852085  0\n",
       "12  5.0  5.0   8.845012  0\n",
       "13  2.0  4.0  12.951186  1\n",
       "14  7.0  6.0  11.854058  0\n",
       "15  3.0  5.0  10.272491  0\n",
       "16  2.0  4.0  10.128849  0\n",
       "17  3.0  3.0  12.440408  0\n",
       "18  3.0  2.0  11.028291  0\n",
       "19  3.0  2.0  12.732264  1\n",
       "20  2.0  6.0  10.550466  1\n",
       "21  5.0  2.0   7.379811  0\n",
       "22  4.0  1.0   7.815355  0\n",
       "23  6.0  2.0   8.059168  1\n",
       "24  3.0  2.0   8.235369  0\n",
       "25  5.0  7.0   9.143197  1\n",
       "26  6.0  6.0   8.195049  0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DataSet(np.array([\n",
    "    np.random.randint(2,9, 27),\n",
    "    np.random.randint(1,9, 27),\n",
    "    np.random.normal(loc=10, scale=2, size=27)\n",
    "]).T, features=['x1', 'x2', 'x1'], y=np.random.randint(0,2, 27), name=\"Sample Data\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.071137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.999822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.821084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.643734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.530007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.314699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.542695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.032778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.806657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.252529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.952814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.852085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.845012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.951186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.854058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.272491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.128849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.440408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.028291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.732264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.550466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.379811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.815355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.059168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.235369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.143197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.195049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1   x2         x1  y\n",
       "0   7.0  5.0  14.071137  0\n",
       "1   7.0  4.0  10.999822  0\n",
       "2   5.0  6.0  11.821084  1\n",
       "3   6.0  3.0   8.643734  0\n",
       "4   8.0  7.0   9.530007  1\n",
       "5   2.0  5.0   9.314699  0\n",
       "6   7.0  8.0   9.542695  1\n",
       "7   5.0  8.0  10.032778  0\n",
       "8   7.0  4.0  13.806657  1\n",
       "9   5.0  6.0  11.252529  1\n",
       "10  6.0  4.0   9.952814  1\n",
       "11  5.0  7.0  10.852085  0\n",
       "12  5.0  5.0   8.845012  0\n",
       "13  2.0  4.0  12.951186  1\n",
       "14  7.0  6.0  11.854058  0\n",
       "15  3.0  5.0  10.272491  0\n",
       "16  2.0  4.0  10.128849  0\n",
       "17  3.0  3.0  12.440408  0\n",
       "18  3.0  2.0  11.028291  0\n",
       "19  3.0  2.0  12.732264  1\n",
       "20  2.0  6.0  10.550466  1\n",
       "21  5.0  2.0   7.379811  0\n",
       "22  4.0  1.0   7.815355  0\n",
       "23  6.0  2.0   8.059168  1\n",
       "24  3.0  2.0   8.235369  0\n",
       "25  5.0  7.0   9.143197  1\n",
       "26  6.0  6.0   8.195049  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x1', 'x2', 'x1'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  5.        , 14.07113691],\n",
       "       [ 7.        ,  4.        , 10.99982182],\n",
       "       [ 5.        ,  6.        , 11.82108367],\n",
       "       [ 6.        ,  3.        ,  8.64373365],\n",
       "       [ 8.        ,  7.        ,  9.53000722],\n",
       "       [ 2.        ,  5.        ,  9.31469862],\n",
       "       [ 7.        ,  8.        ,  9.54269509],\n",
       "       [ 5.        ,  8.        , 10.03277825],\n",
       "       [ 7.        ,  4.        , 13.80665662],\n",
       "       [ 5.        ,  6.        , 11.25252891],\n",
       "       [ 6.        ,  4.        ,  9.95281416],\n",
       "       [ 5.        ,  7.        , 10.85208498],\n",
       "       [ 5.        ,  5.        ,  8.84501223],\n",
       "       [ 2.        ,  4.        , 12.9511859 ],\n",
       "       [ 7.        ,  6.        , 11.85405818],\n",
       "       [ 3.        ,  5.        , 10.27249061],\n",
       "       [ 2.        ,  4.        , 10.12884872],\n",
       "       [ 3.        ,  3.        , 12.44040794],\n",
       "       [ 3.        ,  2.        , 11.02829054],\n",
       "       [ 3.        ,  2.        , 12.73226393],\n",
       "       [ 2.        ,  6.        , 10.55046606],\n",
       "       [ 5.        ,  2.        ,  7.37981145],\n",
       "       [ 4.        ,  1.        ,  7.81535473],\n",
       "       [ 6.        ,  2.        ,  8.05916833],\n",
       "       [ 3.        ,  2.        ,  8.23536944],\n",
       "       [ 5.        ,  7.        ,  9.14319727],\n",
       "       [ 6.        ,  6.        ,  8.19504925]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  5.        , 14.07113691],\n",
       "       [ 7.        ,  4.        , 10.99982182],\n",
       "       [ 5.        ,  6.        , 11.82108367],\n",
       "       [ 6.        ,  3.        ,  8.64373365],\n",
       "       [ 8.        ,  7.        ,  9.53000722],\n",
       "       [ 2.        ,  5.        ,  9.31469862],\n",
       "       [ 7.        ,  8.        ,  9.54269509],\n",
       "       [ 5.        ,  8.        , 10.03277825],\n",
       "       [ 7.        ,  4.        , 13.80665662],\n",
       "       [ 5.        ,  6.        , 11.25252891],\n",
       "       [ 6.        ,  4.        ,  9.95281416],\n",
       "       [ 5.        ,  7.        , 10.85208498],\n",
       "       [ 5.        ,  5.        ,  8.84501223],\n",
       "       [ 2.        ,  4.        , 12.9511859 ],\n",
       "       [ 7.        ,  6.        , 11.85405818],\n",
       "       [ 3.        ,  5.        , 10.27249061],\n",
       "       [ 2.        ,  4.        , 10.12884872],\n",
       "       [ 3.        ,  3.        , 12.44040794],\n",
       "       [ 3.        ,  2.        , 11.02829054],\n",
       "       [ 3.        ,  2.        , 12.73226393],\n",
       "       [ 2.        ,  6.        , 10.55046606],\n",
       "       [ 5.        ,  2.        ,  7.37981145],\n",
       "       [ 4.        ,  1.        ,  7.81535473],\n",
       "       [ 6.        ,  2.        ,  8.05916833],\n",
       "       [ 3.        ,  2.        ,  8.23536944],\n",
       "       [ 5.        ,  7.        ,  9.14319727],\n",
       "       [ 6.        ,  6.        ,  8.19504925]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample Data'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "\n",
    "The above class also supports a few useful methods. One such method is for shuffling the data, which we do often before training. This method returns a new DataSet instance with the shuffled data. Here is how this method is implemented:\n",
    "\n",
    "```python\n",
    "    ...\n",
    "    def shuffled(self, random_state=None):\n",
    "        rgen = np.random.RandomState(random_state)\n",
    "        indexes = np.arange(self.N)\n",
    "        rgen.shuffle(indexes)\n",
    "        return DataSet(self.__examples.iloc[indexes])\n",
    "   ...\n",
    "```\n",
    "\n",
    "Here is an example using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     x1   x2         x1  y\n",
       "22  7.0  7.0   8.610422  1\n",
       "11  7.0  7.0   6.919561  1\n",
       "0   8.0  4.0  10.041026  1\n",
       "1   4.0  6.0   7.976706  1\n",
       "12  7.0  3.0   8.532990  0\n",
       "25  8.0  2.0   8.868058  0\n",
       "7   8.0  8.0  13.279906  1\n",
       "5   8.0  3.0   9.438017  1\n",
       "8   8.0  3.0  11.907139  1\n",
       "4   2.0  1.0  10.987137  0\n",
       "14  8.0  8.0  10.109049  1\n",
       "2   8.0  4.0   8.939255  1\n",
       "15  8.0  7.0   9.092498  1\n",
       "6   6.0  6.0   7.827284  0\n",
       "20  4.0  3.0   7.958531  0\n",
       "18  4.0  8.0   8.609564  0\n",
       "9   4.0  3.0   7.529688  1\n",
       "19  5.0  5.0  13.056071  1\n",
       "16  6.0  8.0  11.481829  1\n",
       "10  8.0  5.0   8.559268  0\n",
       "3   5.0  5.0   8.240834  1\n",
       "21  5.0  2.0  11.155936  0\n",
       "24  3.0  4.0   6.478901  1\n",
       "26  6.0  5.0  10.382259  1\n",
       "13  4.0  8.0   8.980648  1\n",
       "17  2.0  8.0   9.513256  0\n",
       "23  7.0  8.0  10.539011  1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DataSet(np.array([\n",
    "    np.random.randint(2,9, 27),\n",
    "    np.random.randint(1,9, 27),\n",
    "    np.random.normal(loc=10, scale=2, size=27)\n",
    "]).T, features=['x1', 'x2', 'x1'], y=np.random.randint(0,2, 27), name=\"Sample Data\")\n",
    "\n",
    "\n",
    "ds.shuffled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting a dataset into training and test datasets\n",
    "\n",
    "Another useful method provided by the above dataset class is the `train_test_split` method. This method splits the dataset into a training and test sets. Here is how this method is implemented:\n",
    "\n",
    "```python\n",
    "    ...\n",
    "    def train_test_split(self,start=0, end=None, test_portion=None, shuffle=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the dataset into a training set and atest set. \n",
    "        If test_portion is specified, return that portion of the dataset as test \n",
    "        and the rest as training. \n",
    "        Otherwise, return the examples between start and end as test and the \n",
    "        rest as training.\n",
    "        \"\"\"\n",
    "        indexes = np.arange(self.N)\n",
    "        if shuffle is True:\n",
    "            rgen = np.random.RandomState(random_state)\n",
    "            rgen.shuffle(indexes)\n",
    "\n",
    "        if test_portion is None:\n",
    "            end = end or self.N\n",
    "        else:\n",
    "            if not isinstance(test_portion, float) or test_portion < 0 or test_portion > 1:\n",
    "                raise TypeError(\"Only fractions between ]0,1[ are allowed\")\n",
    "\n",
    "            start = self.N - int(self.N * test_portion)\n",
    "            end = self.N\n",
    "\n",
    "        test = DataSet(self.examples.iloc[indexes[range(start, end)]])\n",
    "        train = DataSet(pd.concat([self.examples.iloc[indexes[range(start)]], \n",
    "                                      self.examples.iloc[indexes[range(end, self.N)]]], axis=0))    \n",
    "        return train, test\n",
    "   ...\n",
    "```\n",
    "\n",
    "If the `start` and end `end` parameters exist, the method returns the examples before them as test and the rest of the data as training. If `test_portion` is provided, then that portion of the data is returned as test and the rest as training. The `shuffle` parameter can be used to instruct the method to shuffle the data before splitting it. The method finally returns two dataset instances: training and test sets.\n",
    "\n",
    "Here is an example using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set = \n",
      "      x1   x2         x1  y\n",
      "0   7.0  3.0  11.506196  1\n",
      "1   8.0  5.0  10.905182  1\n",
      "2   4.0  5.0   9.054415  0\n",
      "3   8.0  8.0  10.423384  0\n",
      "4   6.0  5.0   9.488277  0\n",
      "5   5.0  3.0   6.281749  0\n",
      "6   3.0  6.0  10.770672  0\n",
      "7   4.0  1.0   9.551137  1\n",
      "8   8.0  5.0  11.872486  1\n",
      "9   2.0  2.0  10.019604  1\n",
      "10  4.0  5.0  10.099496  1\n",
      "11  2.0  4.0   9.350159  0\n",
      "12  8.0  7.0   9.219867  0\n",
      "13  4.0  4.0   9.946844  1\n",
      "14  4.0  5.0  16.170566  0\n",
      "15  5.0  6.0   8.283784  0\n",
      "16  7.0  4.0   9.858579  1\n",
      "17  8.0  6.0   5.834166  1\n",
      "18  4.0  2.0  10.303100  0\n",
      "19  4.0  3.0  11.199927  0\n",
      "20  7.0  5.0   8.724143  0\n",
      "Test set = \n",
      "      x1   x2         x1  y\n",
      "21  7.0  4.0  11.350370  0\n",
      "22  4.0  4.0  13.075067  1\n",
      "23  2.0  4.0  10.234860  1\n",
      "24  5.0  7.0  10.154091  0\n",
      "25  6.0  2.0   8.094857  0\n",
      "26  2.0  2.0   6.011618  0\n"
     ]
    }
   ],
   "source": [
    "ds = DataSet(np.array([\n",
    "    np.random.randint(2,9, 27),\n",
    "    np.random.randint(1,9, 27),\n",
    "    np.random.normal(loc=10, scale=2, size=27)\n",
    "]).T, features=['x1', 'x2', 'x1'], y=np.random.randint(0,2, 27), name=\"Sample Data\")\n",
    "\n",
    "\n",
    "ta, te = ds.train_test_split(test_portion=.25, shuffle=False, random_state=17)\n",
    "print('Training set = \\n', ta)\n",
    "print('Test set = \\n', te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this dataset class inside other notebooks\n",
    "\n",
    "This class is part of the `mylib` library of this class with is provided to you. Here is how to import this library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylib as my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once imported, one can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set = \n",
      "      x1   x2         x1  y\n",
      "0   2.0  7.0  12.887140  1\n",
      "1   4.0  5.0   9.683472  0\n",
      "2   3.0  3.0  10.322752  1\n",
      "3   5.0  7.0   5.791450  1\n",
      "4   7.0  5.0   7.556257  1\n",
      "5   8.0  5.0   7.276206  0\n",
      "6   2.0  7.0  12.139865  1\n",
      "7   5.0  3.0  12.603362  1\n",
      "8   4.0  4.0   9.702698  0\n",
      "9   6.0  8.0   8.819233  0\n",
      "10  5.0  7.0   8.986496  0\n",
      "11  2.0  1.0   8.620929  1\n",
      "12  5.0  6.0  10.357897  1\n",
      "13  8.0  2.0   7.220334  1\n",
      "14  3.0  3.0   8.465271  0\n",
      "15  5.0  7.0  10.082646  0\n",
      "16  5.0  4.0   9.471886  0\n",
      "17  5.0  6.0   8.229844  1\n",
      "18  4.0  3.0  12.095454  1\n",
      "19  4.0  7.0  10.265396  1\n",
      "20  6.0  7.0   6.748197  1\n",
      "Test set = \n",
      "      x1   x2         x1  y\n",
      "21  5.0  8.0  11.178396  1\n",
      "22  5.0  7.0  12.315620  0\n",
      "23  4.0  5.0  11.591339  1\n",
      "24  4.0  6.0   9.993349  1\n",
      "25  4.0  7.0  10.976606  0\n",
      "26  4.0  2.0   7.586242  0\n"
     ]
    }
   ],
   "source": [
    "ds = my.DataSet(np.array([\n",
    "    np.random.randint(2,9, 27),\n",
    "    np.random.randint(1,9, 27),\n",
    "    np.random.normal(loc=10, scale=2, size=27)\n",
    "]).T, features=['x1', 'x2', 'x1'], y=np.random.randint(0,2, 27), name=\"Sample Data\")\n",
    "\n",
    "\n",
    "ta, te = ds.train_test_split(test_portion=.25, shuffle=False, random_state=17)\n",
    "print('Training set = \\n', ta)\n",
    "print('Test set = \\n', te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "Refactor the above DataSet class by adding a method named `train_validation_test_split` to it. This method should split the data into three sets: training, validation, and test. This method should receive a dictionary parameter named `portions` specifying how much of the data is in each set. For a 75%/15%/10% split, one can use the following portions parameter:\n",
    "\n",
    "```python\n",
    "portions={\"training\": .75, 'validation': .15, 'test': .10 }\n",
    "```\n",
    "\n",
    "The method should support the `shuffle` parameter as well. You may call the `train_test_split` method internally. Make sure to include a comment describing how your implementation of the method works. Test your method on the `ds` dataset above and show that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: \n",
      "\n",
      "      x1   x2         x1  y\n",
      "0   3.0  5.0  10.301051  0\n",
      "1   4.0  5.0   8.230561  0\n",
      "2   4.0  3.0   8.256209  1\n",
      "3   2.0  4.0  11.183143  0\n",
      "4   7.0  2.0   6.950015  0\n",
      "5   5.0  6.0  10.610652  0\n",
      "6   6.0  4.0   8.670299  1\n",
      "7   3.0  2.0   9.745855  0\n",
      "8   5.0  8.0   9.002924  1\n",
      "9   4.0  7.0   9.398452  1\n",
      "10  8.0  6.0  12.342579  0\n",
      "11  3.0  1.0   8.958457  0\n",
      "12  3.0  8.0  11.881169  1\n",
      "13  5.0  1.0   6.823429  0\n",
      "14  6.0  4.0  10.117719  0\n",
      "15  7.0  1.0   9.964405  1\n",
      "16  7.0  6.0  11.597774  0\n",
      "17  5.0  5.0   9.318671  0\n",
      "18  3.0  5.0   8.810315  0\n",
      "19  4.0  2.0   8.233956  1\n",
      "20  7.0  5.0   6.993485  1\n",
      "21  4.0  7.0   9.835555  0\n",
      "22  6.0  1.0  11.634258  1\n",
      "23  8.0  3.0  10.699003  1\n",
      "\n",
      "Validation set: \n",
      "      x1   x2         x1  y\n",
      "24  5.0  6.0  10.614052  0\n",
      "\n",
      "Test set: \n",
      "\n",
      "      x1   x2         x1  y\n",
      "25  5.0  1.0  10.916891  1\n",
      "26  8.0  1.0   9.575260  1\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "def train_validation_test_split(self, portions, shuffle=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the data into train, validation, and test sets.\n",
    "        Will receive a dictionary parameter named portions specifying \n",
    "        how much of the data is in each set.\n",
    "        \"\"\"\n",
    "        \n",
    "        indexes = np.arange(self.N)\n",
    "        if shuffle is True:\n",
    "            rgen = np.random.RandomState(random_state)\n",
    "            rgen.shuffle(indexes)\n",
    "            \n",
    "        'Use Dictionary.get() to get the values out of the portions'\n",
    "        trainVal = portions.get(\"training\")\n",
    "        validVal = portions.get(\"validation\")\n",
    "        testVal = portions.get(\"test\")  \n",
    "        \n",
    "        \"\"\"\n",
    "        Here we are using train_test_split to break the set into its first two parts.\n",
    "        We will have the set of data remaining (the validation and training) and the\n",
    "        test set\n",
    "        \"\"\"\n",
    "        dataLeft, test = self.train_test_split(test_portion=testVal, shuffle=False)\n",
    "        \n",
    "        '''\n",
    "        We will then find the portion of the remaining data that will be used for validation\n",
    "        by using the original vaildVal to find the total number in the original dataset.\n",
    "        Then we will get a new percentage by taking that number and dividing it by the new\n",
    "        total in the new dataset.\n",
    "        '''\n",
    "        validStart = self.N - int(self.N * validVal)\n",
    "        \n",
    "        validPortion = validStart/dataLeft.N\n",
    "        \n",
    "        \"\"\"\n",
    "        We will then do the train_test_split on our new dataLeft set to get our validation and training sets\n",
    "        \"\"\"\n",
    "        \n",
    "        train, validation = dataLeft.train_test_split(test_portion=validPortion, shuffle=False)\n",
    "        \n",
    "        return train, validation, test\n",
    "\n",
    "ds = DataSet(np.array([\n",
    "    np.random.randint(2,9, 27),\n",
    "    np.random.randint(1,9, 27),\n",
    "    np.random.normal(loc=10, scale=2, size=27)\n",
    "]).T, features=['x1', 'x2', 'x1'], y=np.random.randint(0,2, 27), name=\"Sample Data\")\n",
    "\n",
    "\n",
    "portions={\"training\": .75, 'validation': .15, 'test': .10 }\n",
    "\n",
    "train, validation, test = ds.train_validation_test_split(portions={\"training\": .75, 'validation': .15, 'test': .10 }\n",
    "                                                      , shuffle=True)\n",
    "\n",
    "print('Training set: \\n\\n', train)\n",
    "print('\\nValidation set: \\n', validation)\n",
    "print('\\nTest set: \\n\\n', test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
